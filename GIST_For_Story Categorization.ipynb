{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9132fe-784f-4d2b-8cd7-f063fd3c728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "606f83a6-27d5-4a95-ae96-a3273c292c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"650_stories_summaries.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25e6bc81-0f9d-4974-b178-3695d38f0cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping:\n",
      "Comedy & Satire: 0\n",
      "Drama & Romance: 1\n",
      "Historical & Period: 2\n",
      "Mystery & Thriller: 3\n",
      "Science Fiction & Fantasy: 4\n",
      "       id                               title  \\\n",
      "0  457580   The Chronicles of the Cosmic Rift   \n",
      "1  297904        Eldoria's Enchanted Whispers   \n",
      "2  620436         Echoes of Whispered Shadows   \n",
      "3  634687  Emerald Amulet Chronicles Revealed   \n",
      "4  513427        The Shadows of St. Augustine   \n",
      "\n",
      "                                               story                 genre  \\\n",
      "0  In the year 2250, Earth had made significant s...       Science Fiction   \n",
      "1  In a land far away, where the sun shone bright...               Fantasy   \n",
      "2  Once upon a time, in a small, tranquil town ca...               Mystery   \n",
      "3  Once upon a time in the 16th century, a small ...  Historical Adventure   \n",
      "4  In the sun-drenched coastal city of St. August...              Thriller   \n",
      "\n",
      "                 broad_genre  \\\n",
      "0  Science Fiction & Fantasy   \n",
      "1  Science Fiction & Fantasy   \n",
      "2         Mystery & Thriller   \n",
      "3        Historical & Period   \n",
      "4         Mystery & Thriller   \n",
      "\n",
      "                                            summary2  encoded_genre  \n",
      "0  The year is 2250 and the United Earth Governme...              4  \n",
      "1  The story begins with the story of Thorn, a yo...              4  \n",
      "2  The book opens with a description of the town ...              3  \n",
      "3  The book begins with a small English village, ...              2  \n",
      "4  Alex, a 26 year old marine biologist, is just ...              3  \n"
     ]
    }
   ],
   "source": [
    "# Initialize LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the \"broad_genre\" column of the filtered DataFrame\n",
    "df['encoded_genre'] = label_encoder.fit_transform(df['broad_genre'])\n",
    "\n",
    "# Print the mapping of original labels to encoded labels\n",
    "print(\"Label Encoding Mapping:\")\n",
    "for label, code in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "    print(f\"{label}: {code}\")\n",
    "\n",
    "# Display the filtered DataFrame with the encoded column\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe86cb64-b779-407a-b195-b758d84d0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Science Fiction & Fantasy' 'Mystery & Thriller' 'Historical & Period'\n",
      " 'Comedy & Satire' 'Drama & Romance']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"broad_genre\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67928264-b092-40c8-b39e-88a17b53a3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at avsolatorio/GIST-small-Embedding-v0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 260/260 [00:21<00:00, 11.96it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 89.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 389.6938863992691, Accuracy: 0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:21<00:00, 11.85it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 102.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Loss: 273.6116504371166, Accuracy: 0.6615384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:21<00:00, 12.00it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 89.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Loss: 166.0394633114338, Accuracy: 0.7461538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:23<00:00, 11.14it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 86.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Loss: 96.35734960436821, Accuracy: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:22<00:00, 11.38it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 90.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Loss: 51.364373199641705, Accuracy: 0.7384615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:23<00:00, 11.20it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 91.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Loss: 36.99944946542382, Accuracy: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:21<00:00, 12.21it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 93.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Loss: 19.524305820465088, Accuracy: 0.7461538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:21<00:00, 11.93it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 99.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Loss: 13.52270040474832, Accuracy: 0.676923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:20<00:00, 12.75it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 97.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Loss: 16.871002551168203, Accuracy: 0.7076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:22<00:00, 11.37it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 98.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Loss: 11.084627692587674, Accuracy: 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:23<00:00, 11.23it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 101.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Loss: 4.268563042394817, Accuracy: 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:22<00:00, 11.66it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 101.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Loss: 3.131741087883711, Accuracy: 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:22<00:00, 11.41it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 97.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Loss: 2.5162442275322974, Accuracy: 0.7230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:22<00:00, 11.55it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 98.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Loss: 2.0542876278050244, Accuracy: 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:22<00:00, 11.43it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 98.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Loss: 1.7019501589238644, Accuracy: 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare Data\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        story = self.data.iloc[index]['story']\n",
    "        genre = self.data.iloc[index]['encoded_genre']\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            story,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(genre, dtype=torch.long)  # Assuming genre labels are already encoded numerically\n",
    "        }\n",
    "\n",
    "MAX_LENGTH = 150  # Define the maximum sequence length\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"avsolatorio/GIST-small-Embedding-v0\")\n",
    "dataset = CustomDataset(df, tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "# Step 2: Split Data\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Load Pretrained Model\n",
    "num_labels = len(df['broad_genre'].unique())\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"avsolatorio/GIST-small-Embedding-v0\", num_labels=num_labels)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "# Step 4: Fine-Tuning\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 15\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=2, shuffle=False)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Step 5: Evaluate Model\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predictions.extend(preds)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e371d75e-11ef-41f4-b518-a0c021d0a426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc6d783355f4038b7a116068d5931ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "406794b5-167b-45a2-afc8-337981e94fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279bb55026d04b68ba439cf6f2ff26e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/pranaysaggar/GIST_small_genre_categorizer/commit/3d6751c5983ace188a54bacee124a4909057601e', commit_message='Upload BertForSequenceClassification', commit_description='', oid='3d6751c5983ace188a54bacee124a4909057601e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./finetune_GIST_model\")  # Save model files to a local directory\n",
    "\n",
    "# Load the saved model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./finetune_GIST_model\")\n",
    "# Push the model to the Hugging Face Model Hub\n",
    "tokenizer.push_to_hub(\"pranaysaggar/GIST_small_genre_categorizer\")\n",
    "model.push_to_hub(\"pranaysaggar/GIST_small_genre_categorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08fdd86e-517e-4854-b52b-ab84d438c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "ds = load_dataset(\"skeskinen/TinyStories-GPT4\")\n",
    "df1=ds['train'].select(range(60000)).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7ad31f-40c6-4f0b-adc4-2e9397664dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>words</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time, there was a big red cat name...</td>\n",
       "      <td>Tom the big red cat loves to sing and tries ou...</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Write a short story (3-5 paragraphs) which onl...</td>\n",
       "      <td>[receive, opera, red]</td>\n",
       "      <td>[BadEnding, Twist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One day, a boy named Tom found a big blue shee...</td>\n",
       "      <td>Tom and Sam make a big tent with a blue sheet,...</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Write a short story (3-5 paragraphs) which onl...</td>\n",
       "      <td>[use, sheet, blue]</td>\n",
       "      <td>[Dialogue, Twist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One day, a big bus went down the road. A littl...</td>\n",
       "      <td>Tim and his mom ride a bus, and Tim learns to ...</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Write a short story (3-5 paragraphs) which onl...</td>\n",
       "      <td>[relax, bus, uncomfortable]</td>\n",
       "      <td>[Dialogue, Foreshadowing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One day, a little cricket named Tom wanted to ...</td>\n",
       "      <td>Tom the cricket sails on a wide leaf boat and ...</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Write a short story (3-5 paragraphs) which onl...</td>\n",
       "      <td>[sail, cricket, wide]</td>\n",
       "      <td>[Dialogue, Twist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there was a creative little ...</td>\n",
       "      <td>Lisa prays for a sad pigeon to be happy and ha...</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Write a short story (3-5 paragraphs) which onl...</td>\n",
       "      <td>[pray, pigeon, creative]</td>\n",
       "      <td>[BadEnding]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Once upon a time, there was a big red cat name...   \n",
       "1  One day, a boy named Tom found a big blue shee...   \n",
       "2  One day, a big bus went down the road. A littl...   \n",
       "3  One day, a little cricket named Tom wanted to ...   \n",
       "4  Once upon a time, there was a creative little ...   \n",
       "\n",
       "                                             summary source  \\\n",
       "0  Tom the big red cat loves to sing and tries ou...  GPT-4   \n",
       "1  Tom and Sam make a big tent with a blue sheet,...  GPT-4   \n",
       "2  Tim and his mom ride a bus, and Tim learns to ...  GPT-4   \n",
       "3  Tom the cricket sails on a wide leaf boat and ...  GPT-4   \n",
       "4  Lisa prays for a sad pigeon to be happy and ha...  GPT-4   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Write a short story (3-5 paragraphs) which onl...   \n",
       "1  Write a short story (3-5 paragraphs) which onl...   \n",
       "2  Write a short story (3-5 paragraphs) which onl...   \n",
       "3  Write a short story (3-5 paragraphs) which onl...   \n",
       "4  Write a short story (3-5 paragraphs) which onl...   \n",
       "\n",
       "                         words                   features  \n",
       "0        [receive, opera, red]         [BadEnding, Twist]  \n",
       "1           [use, sheet, blue]          [Dialogue, Twist]  \n",
       "2  [relax, bus, uncomfortable]  [Dialogue, Foreshadowing]  \n",
       "3        [sail, cricket, wide]          [Dialogue, Twist]  \n",
       "4     [pray, pigeon, creative]                [BadEnding]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d8b0f9-6943-4921-9ae6-5e1ba46e8758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows...\n",
      "Processed 5000 rows...\n",
      "Processed 10000 rows...\n",
      "Processed 15000 rows...\n",
      "Processed 20000 rows...\n",
      "Processed 25000 rows...\n",
      "Processed 30000 rows...\n",
      "Processed 35000 rows...\n",
      "Processed 40000 rows...\n",
      "Processed 45000 rows...\n",
      "Processed 50000 rows...\n",
      "Processed 55000 rows...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"pranaysaggar/GIST_small_genre_categorizer\"  # Example model name\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Define the genre mapping based on the provided label encoding\n",
    "genre_mapping = {\n",
    "    0: 'Comedy & Satire',\n",
    "    1: 'Drama & Romance',\n",
    "    2: 'Historical & Period',\n",
    "    3: 'Mystery & Thriller',\n",
    "    4: 'Science Fiction & Fantasy'\n",
    "}\n",
    "# Move the model to the GPU device\n",
    "model.to(device)\n",
    "\n",
    "# Function to classify genre for each story\n",
    "# Function to classify genre for each story\n",
    "def classify_genre(story, row_index):\n",
    "    # Tokenize the story and move inputs to the GPU device\n",
    "    inputs = tokenizer(story, return_tensors=\"pt\", truncation=True).to(device)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted genre\n",
    "    predicted_genre_id = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    # Map the predicted genre ID to the actual genre label\n",
    "    predicted_genre = genre_mapping[predicted_genre_id]\n",
    "    \n",
    "    # Print a message after every 5000 rows processed\n",
    "    if row_index % 5000 == 0:\n",
    "        print(f\"Processed {row_index} rows...\")\n",
    "    \n",
    "    return predicted_genre\n",
    "\n",
    "# Apply the model to each story in df1 and store the predicted genre in the 'genre' column\n",
    "for i, row in df1.iterrows():\n",
    "    df1.at[i, 'genre'] = classify_genre(row['story'], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d504087-5a3d-4f0b-bf01-c4aefa55f46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a creative little girl named Lisa. She loved to play and make things with her hands. One day, she saw a pigeon outside her window. The pigeon was sad and alone.\n",
      "Lisa wanted to help the pigeon, so she started to pray. She asked for the pigeon to be happy and have friends. Every day, she would look out the window and pray for the pigeon.\n",
      "But one day, the pigeon was gone. Lisa was sad because her prayers did not work. The pigeon was still alone and had no friends. Lisa learned that sometimes, even when we try our best, things do not always go the way we want them to.\n",
      "Drama & Romance\n"
     ]
    }
   ],
   "source": [
    "print(df1.iloc[4][\"story\"])\n",
    "print(df1.iloc[4][\"genre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9edb47cc-0b81-41fd-a6f4-f1f2495dc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_top_genres(story):\n",
    "    # Tokenize the story\n",
    "    inputs = tokenizer(story, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted genre probabilities\n",
    "    predicted_probabilities = torch.softmax(outputs.logits, dim=1).squeeze().tolist()\n",
    "    \n",
    "    # Get top-k predicted genre IDs\n",
    "    top_k_genre_ids = torch.topk(outputs.logits, k=2, dim=1).indices.squeeze().tolist()\n",
    "    \n",
    "    # Map the predicted genre IDs to the actual genre labels\n",
    "    top_k_genres = [genre_mapping[genre_id] for genre_id in top_k_genre_ids]\n",
    "\n",
    "    return top_k_genres, predicted_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14f5b6a2-7fa0-46f4-bb30-f6bf61318123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Historical & Period', 'Science Fiction & Fantasy'], [0.0006263474933803082, 0.0007921754731796682, 0.9934269189834595, 0.0005412065656855702, 0.004613370168954134])\n"
     ]
    }
   ],
   "source": [
    "st=\"In the heart of 18th century London, a young woman discovers a hidden diary belonging to her ancestors, unraveling tales of forbidden love and political intrigue. As she delves deeper into the past, she uncovers family secrets that have been buried for generations, ultimately leading to a revelation that changes her perception of history forever. Through the pages of the diary, she learns about the struggles and triumphs of her forebears in a time of societal upheaval and cultural transformation.\"\n",
    "print(classify_top_genres(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf974f4-ee0e-4c4b-a29e-9a4fb4dd9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df1, test_size=0.1, random_state=42)\n",
    "\n",
    "# Save train and test DataFrames to separate CSV files\n",
    "train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "test_df.to_csv(\"test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1967b6-23ce-49d8-8e4f-27699212a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words in the summary column: 105\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df1' is your DataFrame with a 'summary' column\n",
    "\n",
    "# Split each summary into words and calculate the number of words\n",
    "word_counts = df1['summary'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Find the maximum number of words\n",
    "max_words = word_counts.max()\n",
    "\n",
    "print(\"Maximum number of words in the summary column:\", max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc1ad7-d6a5-4bf1-81f1-7ac53a3cdcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
